{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "SUKUXK9h8XgL",
      "metadata": {
        "id": "SUKUXK9h8XgL"
      },
      "source": [
        "#**LangChain**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "qo1DQXM18bgL",
      "metadata": {
        "id": "qo1DQXM18bgL"
      },
      "source": [
        "LangChain is a framework for developing applications powered by language models.\n",
        "\n",
        "- GitHub: https://github.com/hwchase17/langchain\n",
        "- Docs: https://python.langchain.com/en/latest/index.html\n",
        "\n",
        "### Overview:\n",
        "- Installation\n",
        "- LLMs\n",
        "- Prompt Templates\n",
        "- Chains\n",
        "- Agents and Tools\n",
        "- Memory\n",
        "- Document Loaders\n",
        "- Indexes"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09CgA1RZkiC4",
      "metadata": {
        "id": "09CgA1RZkiC4"
      },
      "source": [
        "#**Step 01: Installation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "X4tDdLTjkkk_",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4tDdLTjkkk_",
        "outputId": "49739296-a9e9-4b1c-c90c-6e3fe22eb57f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain in c:\\users\\adity\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (0.1.1)\n",
            "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\adity\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in c:\\users\\adity\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\adity\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from langchain) (2.5.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\adity\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from langchain) (0.6.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\adity\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from langchain) (1.33)\n",
            "Requirement already satisfied: langchain-core<0.2,>=0.1.9 in c:\\users\\adity\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from langchain) (0.1.11)\n",
            "Requirement already satisfied: numpy<2,>=1 in c:\\users\\adity\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from langchain) (1.26.2)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\adity\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: langchain-community<0.1,>=0.0.13 in c:\\users\\adity\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from langchain) (0.0.13)\n",
            "Requirement already satisfied: langsmith<0.1.0,>=0.0.77 in c:\\users\\adity\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from langchain) (0.0.81)\n",
            "Requirement already satisfied: requests<3,>=2 in c:\\users\\adity\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\adity\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from langchain) (3.9.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\adity\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from langchain) (2.0.25)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\adity\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\adity\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\adity\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\adity\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\adity\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\adity\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\adity\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.2)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\adity\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in c:\\users\\adity\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from langchain-core<0.2,>=0.1.9->langchain) (23.2)\n",
            "Requirement already satisfied: anyio<5,>=3 in c:\\users\\adity\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from langchain-core<0.2,>=0.1.9->langchain) (4.2.0)\n",
            "Requirement already satisfied: pydantic-core==2.14.6 in c:\\users\\adity\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pydantic<3,>=1->langchain) (2.14.6)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\adity\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\adity\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pydantic<3,>=1->langchain) (4.9.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\adity\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests<3,>=2->langchain) (2.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\adity\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests<3,>=2->langchain) (2023.11.17)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\adity\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests<3,>=2->langchain) (3.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\adity\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\adity\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in c:\\users\\adity\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.9->langchain) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\adity\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.9->langchain) (1.2.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\adity\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.0.1 -> 23.3.2\n",
            "[notice] To update, run: C:\\Users\\adity\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "pip install langchain"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sQHZiF38-Cps",
      "metadata": {
        "id": "sQHZiF38-Cps"
      },
      "source": [
        "#**Step 02: Setup the Environment**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "9-mFf0Ql-KX2",
      "metadata": {
        "id": "9-mFf0Ql-KX2"
      },
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f31c4cc6",
      "metadata": {
        "id": "f31c4cc6"
      },
      "outputs": [],
      "source": [
        "os.environ['OPENAI_API_KEY'] = \"your key here\"\n",
        "\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"your key here\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ed0dc6a",
      "metadata": {
        "id": "9ed0dc6a"
      },
      "source": [
        "##**Step 03: Large Language Models**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "516GZwvpnVpV",
      "metadata": {
        "id": "516GZwvpnVpV"
      },
      "source": [
        "The basic building block of LangChain is a Large Language Model which takes text as input and generates more text"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4FDyNMY3sRMc",
      "metadata": {
        "id": "4FDyNMY3sRMc"
      },
      "source": [
        "Suppose we want to generate a company name based on the company description, so we will first initialize an OpenAI wrapper. In this case, since we want the output to be more random, we will intialize our model with high temprature."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eLqFwlXaH8f4",
      "metadata": {
        "id": "eLqFwlXaH8f4"
      },
      "source": [
        "The temperature parameter adjusts the randomness of the output. Higher values like 0.7 will make the output more random, while lower values like 0.2 will make it more focused and deterministic."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "rMOonq5OH97v",
      "metadata": {
        "id": "rMOonq5OH97v"
      },
      "source": [
        "temperature value--> how creative we want our model to be\n",
        "\n",
        "0 ---> temperature it means model is  very safe it is not taking any bets.\n",
        "\n",
        "1 --> it will take risk it might generate wrong output but it is very creative"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "M9Y34zmZ8xyc",
      "metadata": {
        "id": "M9Y34zmZ8xyc"
      },
      "source": [
        "A generic interface for all LLMs. See all LLM providers: https://python.langchain.com/en/latest/modules/models/llms/integrations.html"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "TB5tAUbT92Z7",
      "metadata": {
        "id": "TB5tAUbT92Z7"
      },
      "source": [
        "#**Open AI**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "BszO_ZXrs95T",
      "metadata": {
        "id": "BszO_ZXrs95T"
      },
      "source": [
        "#**Example 1**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "w-az-0Ex9CaD",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-az-0Ex9CaD",
        "outputId": "a3ac3ffe-5741-43ad-9c57-bea5ee40d925"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai in c:\\users\\adity\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (1.8.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\adity\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\adity\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\adity\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from openai) (2.5.3)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\adity\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from openai) (0.26.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\adity\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from openai) (4.2.0)\n",
            "Requirement already satisfied: tqdm>4 in c:\\users\\adity\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: sniffio in c:\\users\\adity\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: idna>=2.8 in c:\\users\\adity\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\adity\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\adity\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
            "Requirement already satisfied: certifi in c:\\users\\adity\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\adity\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: pydantic-core==2.14.6 in c:\\users\\adity\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pydantic<3,>=1.9.0->openai) (2.14.6)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\adity\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\adity\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tqdm>4->openai) (0.4.6)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.0.1 -> 23.3.2\n",
            "[notice] To update, run: C:\\Users\\adity\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "eaf3880a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-0.0.2.post1-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.6.1 in c:\\users\\adity\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from langchain-openai) (1.8.0)\n",
            "Requirement already satisfied: langchain-core<0.2,>=0.1.7 in c:\\users\\adity\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from langchain-openai) (0.1.11)\n",
            "Requirement already satisfied: numpy<2,>=1 in c:\\users\\adity\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from langchain-openai) (1.26.2)\n",
            "Collecting tiktoken<0.6.0,>=0.5.2\n",
            "  Downloading tiktoken-0.5.2-cp310-cp310-win_amd64.whl (786 kB)\n",
            "     ---------------------------------------- 0.0/786.3 kB ? eta -:--:--\n",
            "     ---------------------------------------- 0.0/786.3 kB ? eta -:--:--\n",
            "     ---------------------------------------- 0.0/786.3 kB ? eta -:--:--\n",
            "      --------------------------------------- 10.2/786.3 kB ? eta -:--:--\n",
            "      --------------------------------------- 10.2/786.3 kB ? eta -:--:--\n",
            "      --------------------------------------- 10.2/786.3 kB ? eta -:--:--\n",
            "     - ----------------------------------- 30.7/786.3 kB 145.2 kB/s eta 0:00:06\n",
            "     - ----------------------------------- 30.7/786.3 kB 145.2 kB/s eta 0:00:06\n",
            "     - ----------------------------------- 41.0/786.3 kB 122.9 kB/s eta 0:00:07\n",
            "     - ----------------------------------- 41.0/786.3 kB 122.9 kB/s eta 0:00:07\n",
            "     -- ---------------------------------- 61.4/786.3 kB 142.2 kB/s eta 0:00:06\n",
            "     -- ---------------------------------- 61.4/786.3 kB 142.2 kB/s eta 0:00:06\n",
            "     --- --------------------------------- 81.9/786.3 kB 158.2 kB/s eta 0:00:05\n",
            "     ---- -------------------------------- 92.2/786.3 kB 163.8 kB/s eta 0:00:05\n",
            "     ----- ------------------------------ 112.6/786.3 kB 192.8 kB/s eta 0:00:04\n",
            "     ----- ------------------------------ 122.9/786.3 kB 189.6 kB/s eta 0:00:04\n",
            "     ------ ----------------------------- 143.4/786.3 kB 207.7 kB/s eta 0:00:04\n",
            "     ------- ---------------------------- 163.8/786.3 kB 223.3 kB/s eta 0:00:03\n",
            "     -------- --------------------------- 194.6/786.3 kB 240.6 kB/s eta 0:00:03\n",
            "     --------- -------------------------- 204.8/786.3 kB 244.1 kB/s eta 0:00:03\n",
            "     ----------- ------------------------ 245.8/786.3 kB 273.9 kB/s eta 0:00:02\n",
            "     ------------ ----------------------- 276.5/786.3 kB 298.8 kB/s eta 0:00:02\n",
            "     -------------- --------------------- 307.2/786.3 kB 316.6 kB/s eta 0:00:02\n",
            "     ---------------- ------------------- 358.4/786.3 kB 353.5 kB/s eta 0:00:02\n",
            "     ----------------- ------------------ 389.1/786.3 kB 372.9 kB/s eta 0:00:02\n",
            "     -------------------- --------------- 450.6/786.3 kB 402.5 kB/s eta 0:00:01\n",
            "     ---------------------- ------------- 501.8/786.3 kB 430.8 kB/s eta 0:00:01\n",
            "     -------------------------- --------- 583.7/786.3 kB 482.7 kB/s eta 0:00:01\n",
            "     ---------------------------- ------- 624.6/786.3 kB 504.0 kB/s eta 0:00:01\n",
            "     ------------------------------ ----- 665.6/786.3 kB 517.7 kB/s eta 0:00:01\n",
            "     ---------------------------------- - 747.5/786.3 kB 555.2 kB/s eta 0:00:01\n",
            "     ------------------------------------ 786.3/786.3 kB 577.4 kB/s eta 0:00:00\n",
            "Requirement already satisfied: langsmith<0.1.0,>=0.0.63 in c:\\users\\adity\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from langchain-core<0.2,>=0.1.7->langchain-openai) (0.0.81)\n",
            "Requirement already satisfied: anyio<5,>=3 in c:\\users\\adity\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from langchain-core<0.2,>=0.1.7->langchain-openai) (4.2.0)\n",
            "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\adity\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from langchain-core<0.2,>=0.1.7->langchain-openai) (2.5.3)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in c:\\users\\adity\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from langchain-core<0.2,>=0.1.7->langchain-openai) (23.2)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\adity\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from langchain-core<0.2,>=0.1.7->langchain-openai) (8.2.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\adity\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from langchain-core<0.2,>=0.1.7->langchain-openai) (6.0.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\adity\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from langchain-core<0.2,>=0.1.7->langchain-openai) (1.33)\n",
            "Requirement already satisfied: requests<3,>=2 in c:\\users\\adity\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from langchain-core<0.2,>=0.1.7->langchain-openai) (2.31.0)\n",
            "Requirement already satisfied: tqdm>4 in c:\\users\\adity\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from openai<2.0.0,>=1.6.1->langchain-openai) (4.66.1)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\adity\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from openai<2.0.0,>=1.6.1->langchain-openai) (0.26.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\adity\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from openai<2.0.0,>=1.6.1->langchain-openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\adity\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from openai<2.0.0,>=1.6.1->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: sniffio in c:\\users\\adity\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from openai<2.0.0,>=1.6.1->langchain-openai) (1.3.0)\n",
            "Collecting regex>=2022.1.18\n",
            "  Downloading regex-2023.12.25-cp310-cp310-win_amd64.whl (269 kB)\n",
            "     ---------------------------------------- 0.0/269.5 kB ? eta -:--:--\n",
            "     --------------------------- ---------- 194.6/269.5 kB 3.9 MB/s eta 0:00:01\n",
            "     -------------------------------------- 269.5/269.5 kB 3.3 MB/s eta 0:00:00\n",
            "Requirement already satisfied: idna>=2.8 in c:\\users\\adity\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.7->langchain-openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\adity\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.7->langchain-openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in c:\\users\\adity\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.6.1->langchain-openai) (2023.11.17)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\adity\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.6.1->langchain-openai) (1.0.2)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\adity\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.6.1->langchain-openai) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\adity\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2,>=0.1.7->langchain-openai) (2.4)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\adity\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pydantic<3,>=1->langchain-core<0.2,>=0.1.7->langchain-openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.14.6 in c:\\users\\adity\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pydantic<3,>=1->langchain-core<0.2,>=0.1.7->langchain-openai) (2.14.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\adity\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests<3,>=2->langchain-core<0.2,>=0.1.7->langchain-openai) (2.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\adity\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests<3,>=2->langchain-core<0.2,>=0.1.7->langchain-openai) (3.3.2)\n",
            "Requirement already satisfied: colorama in c:\\users\\adity\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tqdm>4->openai<2.0.0,>=1.6.1->langchain-openai) (0.4.6)\n",
            "Installing collected packages: regex, tiktoken, langchain-openai\n",
            "Successfully installed langchain-openai-0.0.2.post1 regex-2023.12.25 tiktoken-0.5.2\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.0.1 -> 23.3.2\n",
            "[notice] To update, run: C:\\Users\\adity\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "pip install -U langchain-openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "1bfb6d62",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting huggingface_hubNote: you may need to restart the kernel to use updated packages.\n",
            "\n",
            "  Downloading huggingface_hub-0.20.2-py3-none-any.whl (330 kB)\n",
            "     ---------------------------------------- 0.0/330.3 kB ? eta -:--:--\n",
            "     ---------------------------------------- 0.0/330.3 kB ? eta -:--:--\n",
            "     ---------------------------------------- 0.0/330.3 kB ? eta -:--:--\n",
            "     ---------------------------------------- 0.0/330.3 kB ? eta -:--:--\n",
            "     ---------------------------------------- 0.0/330.3 kB ? eta -:--:--\n",
            "     ---------------------------------------- 0.0/330.3 kB ? eta -:--:--\n",
            "     ---------------------------------------- 0.0/330.3 kB ? eta -:--:--\n",
            "     - -------------------------------------- 10.2/330.3 kB ? eta -:--:--\n",
            "     - -------------------------------------- 10.2/330.3 kB ? eta -:--:--\n",
            "     --- --------------------------------- 30.7/330.3 kB 187.9 kB/s eta 0:00:02\n",
            "     --- --------------------------------- 30.7/330.3 kB 187.9 kB/s eta 0:00:02\n",
            "     ---- -------------------------------- 41.0/330.3 kB 140.3 kB/s eta 0:00:03\n",
            "     ---- -------------------------------- 41.0/330.3 kB 140.3 kB/s eta 0:00:03\n",
            "     ---- -------------------------------- 41.0/330.3 kB 140.3 kB/s eta 0:00:03\n",
            "     ---- -------------------------------- 41.0/330.3 kB 140.3 kB/s eta 0:00:03\n",
            "     ------ ------------------------------ 61.4/330.3 kB 131.3 kB/s eta 0:00:03\n",
            "     ------ ------------------------------ 61.4/330.3 kB 131.3 kB/s eta 0:00:03\n",
            "     --------- --------------------------- 81.9/330.3 kB 143.4 kB/s eta 0:00:02\n",
            "     --------- --------------------------- 81.9/330.3 kB 143.4 kB/s eta 0:00:02\n",
            "     ---------- -------------------------- 92.2/330.3 kB 145.8 kB/s eta 0:00:02\n",
            "     ------------ ----------------------- 112.6/330.3 kB 163.8 kB/s eta 0:00:02\n",
            "     ------------- ---------------------- 122.9/330.3 kB 164.0 kB/s eta 0:00:02\n",
            "     --------------- -------------------- 143.4/330.3 kB 181.4 kB/s eta 0:00:02\n",
            "     ----------------- ------------------ 163.8/330.3 kB 192.7 kB/s eta 0:00:01\n",
            "     ------------------ ----------------- 174.1/330.3 kB 197.9 kB/s eta 0:00:01\n",
            "     --------------------- -------------- 194.6/330.3 kB 214.6 kB/s eta 0:00:01\n",
            "     ---------------------- ------------- 204.8/330.3 kB 218.6 kB/s eta 0:00:01\n",
            "     -------------------------- --------- 245.8/330.3 kB 243.1 kB/s eta 0:00:01\n",
            "     ------------------------------- ---- 286.7/330.3 kB 272.4 kB/s eta 0:00:01\n",
            "     ---------------------------------- - 317.4/330.3 kB 289.3 kB/s eta 0:00:01\n",
            "     ------------------------------------ 330.3/330.3 kB 292.6 kB/s eta 0:00:00\n",
            "Requirement already satisfied: requests in c:\\users\\adity\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from huggingface_hub) (2.31.0)\n",
            "Collecting fsspec>=2023.5.0\n",
            "  Downloading fsspec-2023.12.2-py3-none-any.whl (168 kB)\n",
            "     ---------------------------------------- 0.0/169.0 kB ? eta -:--:--\n",
            "     --------- ----------------------------- 41.0/169.0 kB 1.9 MB/s eta 0:00:01\n",
            "     --------------------------- ---------- 122.9/169.0 kB 1.4 MB/s eta 0:00:01\n",
            "     -------------------------------------- 169.0/169.0 kB 1.4 MB/s eta 0:00:00\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\adity\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from huggingface_hub) (6.0.1)\n",
            "Collecting filelock\n",
            "  Downloading filelock-3.13.1-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: packaging>=20.9 in c:\\users\\adity\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from huggingface_hub) (23.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\adity\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from huggingface_hub) (4.9.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\adity\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from huggingface_hub) (4.66.1)\n",
            "Requirement already satisfied: colorama in c:\\users\\adity\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tqdm>=4.42.1->huggingface_hub) (0.4.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\adity\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests->huggingface_hub) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\adity\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests->huggingface_hub) (2.1.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\adity\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests->huggingface_hub) (3.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\adity\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests->huggingface_hub) (2023.11.17)\n",
            "Installing collected packages: fsspec, filelock, huggingface_hub\n",
            "Successfully installed filelock-3.13.1 fsspec-2023.12.2 huggingface_hub-0.20.2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.0.1 -> 23.3.2\n",
            "[notice] To update, run: C:\\Users\\adity\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "pip install huggingface_hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "lJEy652utDdM",
      "metadata": {
        "id": "lJEy652utDdM"
      },
      "outputs": [],
      "source": [
        "# from langchain.llms import OpenAI\n",
        "from langchain_openai import OpenAI\n",
        "llm = OpenAI(temperature=0.9)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "n_nF4R5EtN_k",
      "metadata": {
        "id": "n_nF4R5EtN_k"
      },
      "source": [
        "And now we will pass in text and get  predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "VIUqmBl3tUgj",
      "metadata": {
        "id": "VIUqmBl3tUgj"
      },
      "outputs": [],
      "source": [
        "text=\"What would be a good company name for a company that makes colorful socks?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "g7itCa0q9rn7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7itCa0q9rn7",
        "outputId": "85af0272-043e-44e5-85ca-b35c2bc6d420"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " \n",
            "\n",
            "Rainbow Toes\n"
          ]
        }
      ],
      "source": [
        "print(llm.predict(text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "2KE0Fngs9daM",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2KE0Fngs9daM",
        "outputId": "558f08de-6402-4f77-8732-ca18345d0b5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\"Rainbow Sox Co.\" or \"Colorful Steps Co.\"\n"
          ]
        }
      ],
      "source": [
        "print(llm(text))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "EJIQT1FSn0Gl",
      "metadata": {
        "id": "EJIQT1FSn0Gl"
      },
      "source": [
        "#**Example 2**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "fa352d5f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fa352d5f",
        "outputId": "a611b824-b84d-4af6-fcf5-edec20bd49c6",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\"Dragon's Palace\" \n"
          ]
        }
      ],
      "source": [
        "from langchain.llms import OpenAI\n",
        "\n",
        "llm = OpenAI(temperature=0.9)\n",
        "name = llm.predict(\"I want to open a restaurant for Chinese food. Suggest a fency name for this.\")\n",
        "print(name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "b56e8581",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b56e8581",
        "outputId": "d3ad1c44-b092-476e-9fc7-f9c396993eec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\"Dragon Court Dining\"\n"
          ]
        }
      ],
      "source": [
        "response=llm(\"I want to open a restaurant for Chinese food. Suggest a fency name for this.\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bj6wjnKZ-bgU",
      "metadata": {
        "id": "bj6wjnKZ-bgU"
      },
      "source": [
        "#**Hugging Face**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "iTsUW116-th1",
      "metadata": {
        "id": "iTsUW116-th1"
      },
      "source": [
        "#**Example 1**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hDMLw7Yr-nQK",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDMLw7Yr-nQK",
        "outputId": "05a08b95-27ca-469e-b960-d14ea5b7836a"
      },
      "outputs": [],
      "source": [
        "!pip install huggingface_hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "B4w0ultA-icd",
      "metadata": {
        "id": "B4w0ultA-icd"
      },
      "outputs": [],
      "source": [
        "from langchain import HuggingFaceHub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "W-pl8cXk-ie7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "W-pl8cXk-ie7",
        "outputId": "06f12d3e-ca9c-42e7-b78f-2e33397cf6f7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\adity\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "C:\\Users\\adity\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\huggingface_hub\\utils\\_deprecation.py:131: FutureWarning: 'InferenceApi' (from 'huggingface_hub.inference_api') is deprecated and will be removed from version '1.0'. `InferenceApi` client is deprecated in favor of the more feature-complete `InferenceClient`. Check out this guide to learn how to convert your script to use it: https://huggingface.co/docs/huggingface_hub/guides/inference#legacy-inferenceapi-client.\n",
            "  warnings.warn(warning_message, FutureWarning)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'Wie alte sind Sie?'"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# https://huggingface.co/google/flan-t5-xl\n",
        "llm = HuggingFaceHub(repo_id=\"google/flan-t5-large\", model_kwargs={\"temperature\":0, \"max_length\":64})\n",
        "\n",
        "llm(\"translate English to German: How old are you?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2MOh4uIm-xDQ",
      "metadata": {
        "id": "2MOh4uIm-xDQ"
      },
      "source": [
        "#**Example 2**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "dmAwr5-d-z6F",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dmAwr5-d-z6F",
        "outputId": "eb956f4c-19e2-4283-aec8-2fdf0f78b907"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\adity\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\huggingface_hub\\utils\\_deprecation.py:131: FutureWarning: 'InferenceApi' (from 'huggingface_hub.inference_api') is deprecated and will be removed from version '1.0'. `InferenceApi` client is deprecated in favor of the more feature-complete `InferenceClient`. Check out this guide to learn how to convert your script to use it: https://huggingface.co/docs/huggingface_hub/guides/inference#legacy-inferenceapi-client.\n",
            "  warnings.warn(warning_message, FutureWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Chinese restaurant\n"
          ]
        }
      ],
      "source": [
        "from langchain import HuggingFaceHub\n",
        "\n",
        "llm = HuggingFaceHub(repo_id=\"google/flan-t5-large\", model_kwargs={\"temperature\":0, \"max_length\":64})\n",
        "name = llm.predict(\"I want to open a restaurant for Chinese food. Suggest a fency name for this.\")\n",
        "print(name)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0782a2dd",
      "metadata": {
        "id": "0782a2dd"
      },
      "source": [
        "##**Step 04: Prompt Templates**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "jszTHb6J_dNV",
      "metadata": {
        "id": "jszTHb6J_dNV"
      },
      "source": [
        "Currently in the above applications we are writing an entire prompt, if you are creating a user directed application then this is not an ideal case\n",
        "\n",
        "LangChain faciliates prompt management and optimization.\n",
        "\n",
        "Normally when you use an LLM in an application, you are not sending user input directly to the LLM. Instead, you need to take the user input and construct a prompt, and only then send that to the LLM."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "unU1DcEv7TWh",
      "metadata": {
        "id": "unU1DcEv7TWh"
      },
      "source": [
        "In many Large Language Model applications we donot pass the user input directly to the Large Language Model, we add the user input to a large piece of text called prompt template"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "IWqka6F_93QB",
      "metadata": {
        "id": "IWqka6F_93QB"
      },
      "source": [
        "#**Example 1**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "7a306b9d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7a306b9d",
        "outputId": "99cb3db2-903d-4faa-fea1-939c142d68cc",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I want to open a restaurant for Italian food. Suggest a fency name for this.\n"
          ]
        }
      ],
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "llm = OpenAI(temperature=0.9)\n",
        "\n",
        "prompt_template_name = PromptTemplate(\n",
        "    input_variables =['cuisine'],\n",
        "    template = \"I want to open a restaurant for {cuisine} food. Suggest a fency name for this.\"\n",
        ")\n",
        "p = prompt_template_name.format(cuisine=\"Italian\")\n",
        "print(p)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "qlKeWd7B95-R",
      "metadata": {
        "id": "qlKeWd7B95-R"
      },
      "source": [
        "#**Example 2**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "qqJZBS9u8534",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "qqJZBS9u8534",
        "outputId": "a1903396-1aa9-4826-d4db-73813e9167ac"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'What is a good name for a company that makes colorful socks'"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "prompt = PromptTemplate.from_template(\"What is a good name for a company that makes {product}\")\n",
        "prompt.format(product=\"colorful socks\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af406b92",
      "metadata": {
        "id": "af406b92"
      },
      "source": [
        "##**Step 05: Chains**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "vGaSSUAIBHdU",
      "metadata": {
        "id": "vGaSSUAIBHdU"
      },
      "source": [
        "Combine LLMs and Prompts in multi-step workflows"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "lcjlXP7z_-k6",
      "metadata": {
        "id": "lcjlXP7z_-k6"
      },
      "source": [
        "Now as we have the  **model**:\n",
        "\n",
        "\n",
        "  llm = OpenAI(temperature=0.9)\n",
        "\n",
        "\n",
        "and the **Prompt Template**:\n",
        "\n",
        "prompt = PromptTemplate.from_template(\"What is a good name for a company that makes {product}\")\n",
        "\n",
        "\n",
        "prompt.format(product=\"colorful socks\")\n",
        "\n",
        "\n",
        "Now using Chains we will link together model and the PromptTemplate and other Chains"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mIJx5zL2BbHJ",
      "metadata": {
        "id": "mIJx5zL2BbHJ"
      },
      "source": [
        "The simplest and most common type of Chain is LLMChain, which passes the input first to Prompt Template and then to Large Language Model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5icZHtlDFrpI",
      "metadata": {
        "id": "5icZHtlDFrpI"
      },
      "source": [
        "LLMChain is responsible to execute the PromptTemplate, For every PromptTemplate we will specifically have an LLMChain"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "MAUSugfLCZH-",
      "metadata": {
        "id": "MAUSugfLCZH-"
      },
      "source": [
        "#**Example 1**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "22NEqcvGGvHJ",
      "metadata": {
        "id": "22NEqcvGGvHJ"
      },
      "outputs": [],
      "source": [
        "from langchain.llms import OpenAI\n",
        "\n",
        "llm = OpenAI(temperature=0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "bK-KESsGGOhY",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "bK-KESsGGOhY",
        "outputId": "5350b017-08b1-4420-e105-b81803992e47"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'What is a good name for a company that makes colorful socks'"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "prompt = PromptTemplate.from_template(\"What is a good name for a company that makes {product}\")\n",
        "prompt.format(product=\"colorful socks\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8KjGw4iXGUGJ",
      "metadata": {
        "id": "8KjGw4iXGUGJ"
      },
      "source": [
        "Whatever input text i am giving that will get assigned to this particular variable that is **product**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "1gatUl_ICZOP",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1gatUl_ICZOP",
        "outputId": "44b68381-262c-47a1-a4df-604706443b38"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\adity\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\"Rainbow Threads\" or \"Colorful Feet Co.\"\n"
          ]
        }
      ],
      "source": [
        "from langchain.chains import LLMChain\n",
        "\n",
        "chain = LLMChain(llm=llm, prompt=prompt)\n",
        "response= chain.run(\"colorful socks\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "O93s1iRICXNv",
      "metadata": {
        "id": "O93s1iRICXNv"
      },
      "source": [
        "#**Example 2**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qV_H_EGCG-OR",
      "metadata": {
        "id": "qV_H_EGCG-OR"
      },
      "outputs": [],
      "source": [
        "from langchain.llms import OpenAI\n",
        "\n",
        "llm = OpenAI(temperature=0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "uLtIkYe6G7xK",
      "metadata": {
        "id": "uLtIkYe6G7xK"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "prompt_template_name = PromptTemplate(\n",
        "    input_variables =['cuisine'],\n",
        "    template = \"I want to open a restaurant for {cuisine} food. Suggest a fency name for this.\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "ba65c213",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ba65c213",
        "outputId": "26ff9d54-ca48-4c32-e85c-5ba4088db01e",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\"La Casa de Sabores\" (The House of Flavors)\n"
          ]
        }
      ],
      "source": [
        "from langchain.chains import LLMChain\n",
        "\n",
        "chain = LLMChain(llm=llm, prompt=prompt_template_name)\n",
        "response=chain.run(\"Mexican\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "e5ccee75",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5ccee75",
        "outputId": "e2cecc1b-230d-47f2-ab47-bb81e014fb2a",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mI want to open a restaurant for Mexican food. Suggest a fency name for this.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\"El Sabor de México\" (The Flavor of Mexico)\n"
          ]
        }
      ],
      "source": [
        "chain = LLMChain(llm=llm, prompt=prompt_template_name, verbose=True)\n",
        "response=chain.run(\"Mexican\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "EMd9OQVNH7lK",
      "metadata": {
        "id": "EMd9OQVNH7lK"
      },
      "source": [
        "#**Can we combine Multiple PromptTemplates, We will try to combine Multiple PromptTemplates**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "nv_tlKtLJLIZ",
      "metadata": {
        "id": "nv_tlKtLJLIZ"
      },
      "source": [
        "#**The output from the first PromptTemplate is passed to the next PromptTemplate as input**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a-6_6H-BJl9L",
      "metadata": {
        "id": "a-6_6H-BJl9L"
      },
      "source": [
        "#**To comine the Chain and  to set a sequence for that we use SimpleSequentialChain**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "87a98d9f",
      "metadata": {
        "id": "87a98d9f"
      },
      "source": [
        "##**Simple Sequential Chain**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "21098937",
      "metadata": {
        "id": "21098937"
      },
      "outputs": [],
      "source": [
        "llm = OpenAI(temperature=0.6)\n",
        "\n",
        "prompt_template_name = PromptTemplate(\n",
        "    input_variables =['cuisine'],\n",
        "    template = \"I want to open a restaurant for {cuisine} food. Suggest a fency name for this.\"\n",
        ")\n",
        "\n",
        "name_chain =LLMChain(llm=llm, prompt=prompt_template_name)\n",
        "\n",
        "prompt_template_items = PromptTemplate(\n",
        "    input_variables = ['restaurant_name'],\n",
        "    template=\"\"\"Suggest some menu items for {restaurant_name}\"\"\"\n",
        ")\n",
        "\n",
        "food_items_chain = LLMChain(llm=llm, prompt=prompt_template_items)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "d9fd9a79",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9fd9a79",
        "outputId": "ec87e143-892a-4695-a534-656c268cfb0d",
        "scrolled": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "1. Spicy Chicken Tikka Masala\n",
            "2. Vegetable Samosas\n",
            "3. Lamb Vindaloo\n",
            "4. Tandoori Shrimp Skewers\n",
            "5. Aloo Gobi (potato and cauliflower curry)\n",
            "6. Chana Masala (chickpea curry)\n",
            "7. Butter Chicken\n",
            "8. Palak Paneer (spinach and cheese curry)\n",
            "9. Naan bread with garlic or onion toppings\n",
            "10. Mango Lassi (yogurt-based drink)\n",
            "11. Dal Makhani (creamy lentil curry)\n",
            "12. Chicken Korma (mild and creamy curry)\n",
            "13. Vegetable Biryani (spiced rice dish)\n",
            "14. Masala Chai (spiced tea)\n",
            "15. Gulab Jamun (fried dough balls in syrup)\n"
          ]
        }
      ],
      "source": [
        "from langchain.chains import SimpleSequentialChain\n",
        "chain = SimpleSequentialChain(chains = [name_chain, food_items_chain])\n",
        "\n",
        "content = chain.run(\"Indian\")\n",
        "print(content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "njqmmiouJ6Uc",
      "metadata": {
        "id": "njqmmiouJ6Uc"
      },
      "source": [
        "#**There is a issue with SimpleSequentialChain it only shows last input information**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hKVVpZo8KC38",
      "metadata": {
        "id": "hKVVpZo8KC38"
      },
      "source": [
        "#**To show the entire information i will use SequentialChain**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0386d05c",
      "metadata": {
        "id": "0386d05c"
      },
      "source": [
        "##**Sequential Chain**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "49dc0fae",
      "metadata": {
        "id": "49dc0fae"
      },
      "outputs": [],
      "source": [
        "llm = OpenAI(temperature=0.7)\n",
        "\n",
        "prompt_template_name = PromptTemplate(\n",
        "    input_variables =['cuisine'],\n",
        "    template = \"I want to open a restaurant for {cuisine} food. Suggest a fency name for this.\"\n",
        ")\n",
        "\n",
        "name_chain =LLMChain(llm=llm, prompt=prompt_template_name, output_key=\"restaurant_name\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "9dea8402",
      "metadata": {
        "id": "9dea8402"
      },
      "outputs": [],
      "source": [
        "llm = OpenAI(temperature=0.7)\n",
        "\n",
        "prompt_template_items = PromptTemplate(\n",
        "    input_variables = ['restaurant_name'],\n",
        "    template=\"Suggest some menu items for {restaurant_name}.\"\n",
        ")\n",
        "\n",
        "food_items_chain =LLMChain(llm=llm, prompt=prompt_template_items, output_key=\"menu_items\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "1ec1be10",
      "metadata": {
        "id": "1ec1be10"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import SequentialChain\n",
        "\n",
        "chain = SequentialChain(\n",
        "    chains = [name_chain, food_items_chain],\n",
        "    input_variables = ['cuisine'],\n",
        "    output_variables = ['restaurant_name', \"menu_items\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "4653c540",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4653c540",
        "outputId": "8162166c-0ee9-4164-9f06-9f1f2fa42e0b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'cuisine': 'Indian',\n",
            " 'menu_items': '\\n'\n",
            "               '\\n'\n",
            "               '1. Spicy Chicken Tikka Masala\\n'\n",
            "               '2. Vegetable Samosas\\n'\n",
            "               '3. Lamb Vindaloo\\n'\n",
            "               '4. Tandoori Shrimp Skewers\\n'\n",
            "               '5. Aloo Gobi (potato and cauliflower curry)\\n'\n",
            "               '6. Chicken Biryani\\n'\n",
            "               '7. Palak Paneer (spinach and cheese curry)\\n'\n",
            "               '8. Tandoori Naan Bread\\n'\n",
            "               '9. Mango Lassi (yogurt drink)\\n'\n",
            "               '10. Coconut Curry Vegetables\\n'\n",
            "               '11. Tandoori Chicken Tikka Kabobs\\n'\n",
            "               '12. Chana Masala (chickpea curry)\\n'\n",
            "               '13. Lamb Rogan Josh\\n'\n",
            "               '14. Vegetable Korma\\n'\n",
            "               '15. Gulab Jamun (sweet fried dough balls in syrup)\\n'\n",
            "               '16. Chicken Jalfrezi (spicy stir-fry)\\n'\n",
            "               '17. Aloo Tikki (potato patties)\\n'\n",
            "               '18. Fish Curry\\n'\n",
            "               '19. Vegetable Biryani\\n'\n",
            "               '20. Chicken Malai Tikka (creamy chicken kabobs)',\n",
            " 'restaurant_name': '\\n\\n\"Spice Palace\"'}\n"
          ]
        }
      ],
      "source": [
        "from pprint import pprint\n",
        "pprint(chain({\"cuisine\": \"Indian\"}))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4069a75e",
      "metadata": {
        "id": "4069a75e"
      },
      "source": [
        "##**Step 06. Agents and Tools**\n",
        "\n",
        "Agents involve an LLM making decisions about which Actions to take, taking that Action, seeing an Observation, and repeating that until done.\n",
        "\n",
        "\n",
        "When used correctly agents can be extremely powerful. In order to load agents, you should understand the following concepts:\n",
        "\n",
        "- Tool: A function that performs a specific duty. This can be things like: Google Search, Database lookup, Python REPL, other chains.\n",
        "- LLM: The language model powering the agent.\n",
        "- Agent: The agent to use.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Z-4QjS31LD_s",
      "metadata": {
        "id": "Z-4QjS31LD_s"
      },
      "source": [
        "Agent is a very powerful concept in LangChain"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "GgNLQ6kSL4na",
      "metadata": {
        "id": "GgNLQ6kSL4na"
      },
      "source": [
        "For example I have to travel from Dubai to Canada, I type this in ChatGPT\n",
        "\n",
        "\n",
        "\n",
        "---> Give me  two flight options from Dubai to Canada on September 1, 2023 | ChatGPT will not be able to answer because has knowledge till\n",
        "September 2021\n",
        "\n",
        "\n",
        "\n",
        "ChatGPT plus has Expedia Plugin, if we enable this plugin it will go to Expedia Plugin and will try to pull information about Flights & it will show the information"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_nC7hejzNcXC",
      "metadata": {
        "id": "_nC7hejzNcXC"
      },
      "source": [
        "#**What exactly happens when we try to enable this plugin**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "DxDAjwe5SMEe",
      "metadata": {
        "id": "DxDAjwe5SMEe"
      },
      "source": [
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "LIuuDLmDNqc7",
      "metadata": {
        "id": "LIuuDLmDNqc7"
      },
      "source": [
        "When we think about LLM. Many people think that it is just a knowledge engine, it has knowledge and it will try to give answer based on that knowledge but the knowledge is only limited to September 2021. The think that most people missout is that Large Lanaguage Model has a reasoning engine, and using that reasoning engine it can figure out when someone types this type of Question\n",
        "\n",
        "\n",
        "Give me  two flight options from Dubai to Canada on September 1, 2023\n",
        "\n",
        "\n",
        "As a human we go to Expedia as we have a reasoning engine in our brain.\n",
        "\n",
        "LLM has a reasoning engine as well, so it will figure out the Source, Destination, Date and it will call Expedia Plugin and it will return response back."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "LJFY2fPgS-hH",
      "metadata": {
        "id": "LJFY2fPgS-hH"
      },
      "source": [
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "xfPzN1KrTAE6",
      "metadata": {
        "id": "xfPzN1KrTAE6"
      },
      "source": [
        "#**How much is US GDP in 2022? plus 5**\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "tvy3lwEJV45L",
      "metadata": {
        "id": "tvy3lwEJV45L"
      },
      "source": [
        "As LLM has a reasoning engine to answer that question it will go to Google Search Tool, it will find that answer and then it will use Math Tool and do plus 5"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "CRLHxrjoWnyr",
      "metadata": {
        "id": "CRLHxrjoWnyr"
      },
      "source": [
        "#**An agent has access to a suite of tools, and determines which ones to use depending on the user input.**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "i6NyOqMmWyr1",
      "metadata": {
        "id": "i6NyOqMmWyr1"
      },
      "source": [
        "#Agent will conenct with external tools and it will use LLM reasoning capabilities"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "J7PXIBojXKHE",
      "metadata": {
        "id": "J7PXIBojXKHE"
      },
      "source": [
        "#All the tools like Google Search Tool and Math Tool are available as part of LangChain and you can configure  agent, so agent is nothing but using all these tools and LLM reasoning capabilities to perform a given task  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "V-v5l0EL5Om7",
      "metadata": {
        "id": "V-v5l0EL5Om7"
      },
      "source": [
        "#To access Google Search Results in Real Time we use serpapi"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "471b2c6b",
      "metadata": {
        "id": "471b2c6b"
      },
      "source": [
        "#### serpapi and llm-math tool"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "MLBZ5wZZYinj",
      "metadata": {
        "id": "MLBZ5wZZYinj"
      },
      "source": [
        "If you're using a text LLM, first try zero-shot-react-description, aka. the MRKL agent for LLMs.\n",
        "\n",
        "\n",
        "If you're using a Chat Model, try chat-zero-shot-react-description, aka. the MRKL agent for Chat Models.\n",
        "\n",
        "\n",
        "If you're using a Chat Model and want to use memory, try chat-conversational-react-description, the Conversational agent.\n",
        "\n",
        "\n",
        "If you have a complex task that requires many steps and you're interested in experimenting with a new type of agent, try the Plan-and-Execute agent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "5Mjy8I20lmdD",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Mjy8I20lmdD",
        "outputId": "026ea46f-a6b1-4663-bbd4-d92b99f94623"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting google-search-results\n",
            "  Downloading google_search_results-2.4.2.tar.gz (18 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Requirement already satisfied: requests in c:\\users\\adity\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from google-search-results) (2.31.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\adity\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests->google-search-results) (3.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\adity\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests->google-search-results) (2023.11.17)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\adity\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests->google-search-results) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\adity\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests->google-search-results) (2.1.0)\n",
            "Installing collected packages: google-search-results\n",
            "  Running setup.py install for google-search-results: started\n",
            "  Running setup.py install for google-search-results: finished with status 'done'\n",
            "Successfully installed google-search-results-2.4.2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  DEPRECATION: google-search-results is being installed using the legacy 'setup.py install' method, because it does not have a 'pyproject.toml' and the 'wheel' package is not installed. pip 23.1 will enforce this behaviour change. A possible replacement is to enable the '--use-pep517' option. Discussion can be found at https://github.com/pypa/pip/issues/8559\n",
            "\n",
            "[notice] A new release of pip is available: 23.0.1 -> 23.3.2\n",
            "[notice] To update, run: C:\\Users\\adity\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install google-search-results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "tkzApnDnJy8p",
      "metadata": {
        "id": "tkzApnDnJy8p"
      },
      "source": [
        "SerpApi is a real-time API to access Google search results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "QOK4FGizmihA",
      "metadata": {
        "id": "QOK4FGizmihA"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# os.environ['SERPAPI_API_KEY'] = 'your key here'\n",
        "\n",
        "# os.environ['OPENAI_API_KEY'] = 'your key here'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "b134afcb",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting numexpr\n",
            "  Downloading numexpr-2.8.8-cp310-cp310-win_amd64.whl (96 kB)\n",
            "     ---------------------------------------- 0.0/96.4 kB ? eta -:--:--\n",
            "     ---- ----------------------------------- 10.2/96.4 kB ? eta -:--:--\n",
            "     ---- ----------------------------------- 10.2/96.4 kB ? eta -:--:--\n",
            "     ---- ----------------------------------- 10.2/96.4 kB ? eta -:--:--\n",
            "     ---- ----------------------------------- 10.2/96.4 kB ? eta -:--:--\n",
            "     ---- ----------------------------------- 10.2/96.4 kB ? eta -:--:--\n",
            "     ---- ----------------------------------- 10.2/96.4 kB ? eta -:--:--\n",
            "     ---- ----------------------------------- 10.2/96.4 kB ? eta -:--:--\n",
            "     ---- ----------------------------------- 10.2/96.4 kB ? eta -:--:--\n",
            "     ------------ -------------------------- 30.7/96.4 kB 54.6 kB/s eta 0:00:02\n",
            "     ------------ -------------------------- 30.7/96.4 kB 54.6 kB/s eta 0:00:02\n",
            "     ---------------- ---------------------- 41.0/96.4 kB 61.4 kB/s eta 0:00:01\n",
            "     ---------------- ---------------------- 41.0/96.4 kB 61.4 kB/s eta 0:00:01\n",
            "     ---------------- ---------------------- 41.0/96.4 kB 61.4 kB/s eta 0:00:01\n",
            "     ---------------- ---------------------- 41.0/96.4 kB 61.4 kB/s eta 0:00:01\n",
            "     ------------------------ -------------- 61.4/96.4 kB 78.0 kB/s eta 0:00:01\n",
            "     ------------------------ -------------- 61.4/96.4 kB 78.0 kB/s eta 0:00:01\n",
            "     ---------------------------- ---------- 71.7/96.4 kB 81.9 kB/s eta 0:00:01\n",
            "     ---------------------------- ---------- 71.7/96.4 kB 81.9 kB/s eta 0:00:01\n",
            "     -------------------------------------- 96.4/96.4 kB 104.1 kB/s eta 0:00:00\n",
            "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\adity\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from numexpr) (1.26.2)\n",
            "Installing collected packages: numexpr\n",
            "Successfully installed numexpr-2.8.8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.0.1 -> 23.3.2\n",
            "[notice] To update, run: C:\\Users\\adity\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install numexpr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "fec4212d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "fec4212d",
        "outputId": "ccc26c62-3d45-47e2-bbe6-bf361f82f2fe",
        "scrolled": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m I should use a calculator to add 5 to the GDP of US in 2022\n",
            "Action: Calculator\n",
            "Action Input: GDP of US in 2022 + 5\u001b[0m"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "LLMMathChain._evaluate(\"\nGDP_US_2022 + 5\n\") raised error: 'GDP_US_2022'. Please try again with a valid numerical expression",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\numexpr\\necompiler.py:761\u001b[0m, in \u001b[0;36mgetArguments\u001b[1;34m(names, local_dict, global_dict, _frame_depth)\u001b[0m\n\u001b[0;32m    760\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 761\u001b[0m     a \u001b[38;5;241m=\u001b[39m \u001b[43mlocal_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    762\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
            "\u001b[1;31mKeyError\u001b[0m: 'GDP_US_2022'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\langchain\\chains\\llm_math\\base.py:89\u001b[0m, in \u001b[0;36mLLMMathChain._evaluate_expression\u001b[1;34m(self, expression)\u001b[0m\n\u001b[0;32m     87\u001b[0m     local_dict \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpi\u001b[39m\u001b[38;5;124m\"\u001b[39m: math\u001b[38;5;241m.\u001b[39mpi, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124me\u001b[39m\u001b[38;5;124m\"\u001b[39m: math\u001b[38;5;241m.\u001b[39me}\n\u001b[0;32m     88\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\n\u001b[1;32m---> 89\u001b[0m         \u001b[43mnumexpr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     90\u001b[0m \u001b[43m            \u001b[49m\u001b[43mexpression\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrip\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     91\u001b[0m \u001b[43m            \u001b[49m\u001b[43mglobal_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# restrict access to globals\u001b[39;49;00m\n\u001b[0;32m     92\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlocal_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# add common mathematical functions\u001b[39;49;00m\n\u001b[0;32m     93\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m     )\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\numexpr\\necompiler.py:976\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(ex, local_dict, global_dict, out, order, casting, sanitize, _frame_depth, **kwargs)\u001b[0m\n\u001b[0;32m    975\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 976\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\numexpr\\necompiler.py:875\u001b[0m, in \u001b[0;36mvalidate\u001b[1;34m(ex, local_dict, global_dict, out, order, casting, _frame_depth, sanitize, **kwargs)\u001b[0m\n\u001b[0;32m    874\u001b[0m names, ex_uses_vml \u001b[38;5;241m=\u001b[39m _names_cache[expr_key]\n\u001b[1;32m--> 875\u001b[0m arguments \u001b[38;5;241m=\u001b[39m \u001b[43mgetArguments\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mglobal_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_frame_depth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_frame_depth\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# Create a signature\u001b[39;00m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\numexpr\\necompiler.py:763\u001b[0m, in \u001b[0;36mgetArguments\u001b[1;34m(names, local_dict, global_dict, _frame_depth)\u001b[0m\n\u001b[0;32m    762\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m--> 763\u001b[0m     a \u001b[38;5;241m=\u001b[39m \u001b[43mglobal_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    764\u001b[0m arguments\u001b[38;5;241m.\u001b[39mappend(numpy\u001b[38;5;241m.\u001b[39masarray(a))\n",
            "\u001b[1;31mKeyError\u001b[0m: 'GDP_US_2022'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[43], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m agent \u001b[38;5;241m=\u001b[39m initialize_agent(tools, llm, agent\u001b[38;5;241m=\u001b[39mAgentType\u001b[38;5;241m.\u001b[39mZERO_SHOT_REACT_DESCRIPTION, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Let's test it out!\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWhat was the GDP of US in 2022 plus 5?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\langchain_core\\_api\\deprecation.py:145\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    143\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    144\u001b[0m     emit_warning()\n\u001b[1;32m--> 145\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\langchain\\chains\\base.py:538\u001b[0m, in \u001b[0;36mChain.run\u001b[1;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[0;32m    536\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    537\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`run` supports only one positional argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 538\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m[\n\u001b[0;32m    539\u001b[0m         _output_key\n\u001b[0;32m    540\u001b[0m     ]\n\u001b[0;32m    542\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[0;32m    543\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m(kwargs, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, tags\u001b[38;5;241m=\u001b[39mtags, metadata\u001b[38;5;241m=\u001b[39mmetadata)[\n\u001b[0;32m    544\u001b[0m         _output_key\n\u001b[0;32m    545\u001b[0m     ]\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\langchain_core\\_api\\deprecation.py:145\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    143\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    144\u001b[0m     emit_warning()\n\u001b[1;32m--> 145\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\langchain\\chains\\base.py:363\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[0;32m    331\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the chain.\u001b[39;00m\n\u001b[0;32m    332\u001b[0m \n\u001b[0;32m    333\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[38;5;124;03m        `Chain.output_keys`.\u001b[39;00m\n\u001b[0;32m    355\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    356\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    357\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks,\n\u001b[0;32m    358\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m: tags,\n\u001b[0;32m    359\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[0;32m    360\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: run_name,\n\u001b[0;32m    361\u001b[0m }\n\u001b[1;32m--> 363\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    364\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    365\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRunnableConfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    366\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    367\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_run_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_run_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    368\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\langchain\\chains\\base.py:162\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    161\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[1;32m--> 162\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    163\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[0;32m    164\u001b[0m final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[0;32m    165\u001b[0m     inputs, outputs, return_only_outputs\n\u001b[0;32m    166\u001b[0m )\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\langchain\\chains\\base.py:156\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    149\u001b[0m run_manager \u001b[38;5;241m=\u001b[39m callback_manager\u001b[38;5;241m.\u001b[39mon_chain_start(\n\u001b[0;32m    150\u001b[0m     dumpd(\u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    151\u001b[0m     inputs,\n\u001b[0;32m    152\u001b[0m     name\u001b[38;5;241m=\u001b[39mrun_name,\n\u001b[0;32m    153\u001b[0m )\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 156\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    158\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[0;32m    159\u001b[0m     )\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    161\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\langchain\\agents\\agent.py:1376\u001b[0m, in \u001b[0;36mAgentExecutor._call\u001b[1;34m(self, inputs, run_manager)\u001b[0m\n\u001b[0;32m   1374\u001b[0m \u001b[38;5;66;03m# We now enter the agent loop (until it returns something).\u001b[39;00m\n\u001b[0;32m   1375\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_continue(iterations, time_elapsed):\n\u001b[1;32m-> 1376\u001b[0m     next_step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_take_next_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1377\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1378\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1379\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1380\u001b[0m \u001b[43m        \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1381\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1382\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1383\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(next_step_output, AgentFinish):\n\u001b[0;32m   1384\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_return(\n\u001b[0;32m   1385\u001b[0m             next_step_output, intermediate_steps, run_manager\u001b[38;5;241m=\u001b[39mrun_manager\n\u001b[0;32m   1386\u001b[0m         )\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\langchain\\agents\\agent.py:1102\u001b[0m, in \u001b[0;36mAgentExecutor._take_next_step\u001b[1;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[0;32m   1093\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_take_next_step\u001b[39m(\n\u001b[0;32m   1094\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1095\u001b[0m     name_to_tool_map: Dict[\u001b[38;5;28mstr\u001b[39m, BaseTool],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1099\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1100\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[AgentFinish, List[Tuple[AgentAction, \u001b[38;5;28mstr\u001b[39m]]]:\n\u001b[0;32m   1101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_consume_next_step(\n\u001b[1;32m-> 1102\u001b[0m         [\n\u001b[0;32m   1103\u001b[0m             a\n\u001b[0;32m   1104\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter_next_step(\n\u001b[0;32m   1105\u001b[0m                 name_to_tool_map,\n\u001b[0;32m   1106\u001b[0m                 color_mapping,\n\u001b[0;32m   1107\u001b[0m                 inputs,\n\u001b[0;32m   1108\u001b[0m                 intermediate_steps,\n\u001b[0;32m   1109\u001b[0m                 run_manager,\n\u001b[0;32m   1110\u001b[0m             )\n\u001b[0;32m   1111\u001b[0m         ]\n\u001b[0;32m   1112\u001b[0m     )\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\langchain\\agents\\agent.py:1102\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1093\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_take_next_step\u001b[39m(\n\u001b[0;32m   1094\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1095\u001b[0m     name_to_tool_map: Dict[\u001b[38;5;28mstr\u001b[39m, BaseTool],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1099\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1100\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[AgentFinish, List[Tuple[AgentAction, \u001b[38;5;28mstr\u001b[39m]]]:\n\u001b[0;32m   1101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_consume_next_step(\n\u001b[1;32m-> 1102\u001b[0m         [\n\u001b[0;32m   1103\u001b[0m             a\n\u001b[0;32m   1104\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter_next_step(\n\u001b[0;32m   1105\u001b[0m                 name_to_tool_map,\n\u001b[0;32m   1106\u001b[0m                 color_mapping,\n\u001b[0;32m   1107\u001b[0m                 inputs,\n\u001b[0;32m   1108\u001b[0m                 intermediate_steps,\n\u001b[0;32m   1109\u001b[0m                 run_manager,\n\u001b[0;32m   1110\u001b[0m             )\n\u001b[0;32m   1111\u001b[0m         ]\n\u001b[0;32m   1112\u001b[0m     )\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\langchain\\agents\\agent.py:1198\u001b[0m, in \u001b[0;36mAgentExecutor._iter_next_step\u001b[1;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[0;32m   1196\u001b[0m         tool_run_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllm_prefix\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1197\u001b[0m     \u001b[38;5;66;03m# We then call the tool on the tool input to get an observation\u001b[39;00m\n\u001b[1;32m-> 1198\u001b[0m     observation \u001b[38;5;241m=\u001b[39m tool\u001b[38;5;241m.\u001b[39mrun(\n\u001b[0;32m   1199\u001b[0m         agent_action\u001b[38;5;241m.\u001b[39mtool_input,\n\u001b[0;32m   1200\u001b[0m         verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[0;32m   1201\u001b[0m         color\u001b[38;5;241m=\u001b[39mcolor,\n\u001b[0;32m   1202\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child() \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1203\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtool_run_kwargs,\n\u001b[0;32m   1204\u001b[0m     )\n\u001b[0;32m   1205\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1206\u001b[0m     tool_run_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magent\u001b[38;5;241m.\u001b[39mtool_run_logging_kwargs()\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\langchain_core\\tools.py:369\u001b[0m, in \u001b[0;36mBaseTool.run\u001b[1;34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[0;32m    367\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mException\u001b[39;00m, \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    368\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_tool_error(e)\n\u001b[1;32m--> 369\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    370\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    371\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_tool_end(\n\u001b[0;32m    372\u001b[0m         \u001b[38;5;28mstr\u001b[39m(observation), color\u001b[38;5;241m=\u001b[39mcolor, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    373\u001b[0m     )\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\langchain_core\\tools.py:341\u001b[0m, in \u001b[0;36mBaseTool.run\u001b[1;34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[0;32m    338\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    339\u001b[0m     tool_args, tool_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_to_args_and_kwargs(parsed_input)\n\u001b[0;32m    340\u001b[0m     observation \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 341\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run(\u001b[38;5;241m*\u001b[39mtool_args, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtool_kwargs)\n\u001b[0;32m    342\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    343\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run(\u001b[38;5;241m*\u001b[39mtool_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtool_kwargs)\n\u001b[0;32m    344\u001b[0m     )\n\u001b[0;32m    345\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ToolException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    346\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_tool_error:\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\langchain_core\\tools.py:512\u001b[0m, in \u001b[0;36mTool._run\u001b[1;34m(self, run_manager, *args, **kwargs)\u001b[0m\n\u001b[0;32m    509\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc:\n\u001b[0;32m    510\u001b[0m     new_argument_supported \u001b[38;5;241m=\u001b[39m signature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m--> 512\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(\n\u001b[0;32m    513\u001b[0m             \u001b[38;5;241m*\u001b[39margs,\n\u001b[0;32m    514\u001b[0m             callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child() \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    515\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    516\u001b[0m         )\n\u001b[0;32m    517\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_argument_supported\n\u001b[0;32m    518\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    519\u001b[0m     )\n\u001b[0;32m    520\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTool does not support sync\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\langchain_core\\_api\\deprecation.py:145\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    143\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    144\u001b[0m     emit_warning()\n\u001b[1;32m--> 145\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\langchain\\chains\\base.py:538\u001b[0m, in \u001b[0;36mChain.run\u001b[1;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[0;32m    536\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    537\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`run` supports only one positional argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 538\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m[\n\u001b[0;32m    539\u001b[0m         _output_key\n\u001b[0;32m    540\u001b[0m     ]\n\u001b[0;32m    542\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[0;32m    543\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m(kwargs, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, tags\u001b[38;5;241m=\u001b[39mtags, metadata\u001b[38;5;241m=\u001b[39mmetadata)[\n\u001b[0;32m    544\u001b[0m         _output_key\n\u001b[0;32m    545\u001b[0m     ]\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\langchain_core\\_api\\deprecation.py:145\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    143\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    144\u001b[0m     emit_warning()\n\u001b[1;32m--> 145\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\langchain\\chains\\base.py:363\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[0;32m    331\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the chain.\u001b[39;00m\n\u001b[0;32m    332\u001b[0m \n\u001b[0;32m    333\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[38;5;124;03m        `Chain.output_keys`.\u001b[39;00m\n\u001b[0;32m    355\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    356\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    357\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks,\n\u001b[0;32m    358\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m: tags,\n\u001b[0;32m    359\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[0;32m    360\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: run_name,\n\u001b[0;32m    361\u001b[0m }\n\u001b[1;32m--> 363\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    364\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    365\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRunnableConfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    366\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    367\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_run_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_run_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    368\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\langchain\\chains\\base.py:162\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    161\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[1;32m--> 162\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    163\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[0;32m    164\u001b[0m final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[0;32m    165\u001b[0m     inputs, outputs, return_only_outputs\n\u001b[0;32m    166\u001b[0m )\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\langchain\\chains\\base.py:156\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    149\u001b[0m run_manager \u001b[38;5;241m=\u001b[39m callback_manager\u001b[38;5;241m.\u001b[39mon_chain_start(\n\u001b[0;32m    150\u001b[0m     dumpd(\u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    151\u001b[0m     inputs,\n\u001b[0;32m    152\u001b[0m     name\u001b[38;5;241m=\u001b[39mrun_name,\n\u001b[0;32m    153\u001b[0m )\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 156\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    158\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[0;32m    159\u001b[0m     )\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    161\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\langchain\\chains\\llm_math\\base.py:158\u001b[0m, in \u001b[0;36mLLMMathChain._call\u001b[1;34m(self, inputs, run_manager)\u001b[0m\n\u001b[0;32m    152\u001b[0m _run_manager\u001b[38;5;241m.\u001b[39mon_text(inputs[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_key])\n\u001b[0;32m    153\u001b[0m llm_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_chain\u001b[38;5;241m.\u001b[39mpredict(\n\u001b[0;32m    154\u001b[0m     question\u001b[38;5;241m=\u001b[39minputs[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_key],\n\u001b[0;32m    155\u001b[0m     stop\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m```output\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    156\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m_run_manager\u001b[38;5;241m.\u001b[39mget_child(),\n\u001b[0;32m    157\u001b[0m )\n\u001b[1;32m--> 158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_llm_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mllm_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_run_manager\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\langchain\\chains\\llm_math\\base.py:112\u001b[0m, in \u001b[0;36mLLMMathChain._process_llm_result\u001b[1;34m(self, llm_output, run_manager)\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text_match:\n\u001b[0;32m    111\u001b[0m     expression \u001b[38;5;241m=\u001b[39m text_match\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m--> 112\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluate_expression\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpression\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    113\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_text(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAnswer: \u001b[39m\u001b[38;5;124m\"\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose)\n\u001b[0;32m    114\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_text(output, color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myellow\u001b[39m\u001b[38;5;124m\"\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\langchain\\chains\\llm_math\\base.py:96\u001b[0m, in \u001b[0;36mLLMMathChain._evaluate_expression\u001b[1;34m(self, expression)\u001b[0m\n\u001b[0;32m     88\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\n\u001b[0;32m     89\u001b[0m         numexpr\u001b[38;5;241m.\u001b[39mevaluate(\n\u001b[0;32m     90\u001b[0m             expression\u001b[38;5;241m.\u001b[39mstrip(),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     93\u001b[0m         )\n\u001b[0;32m     94\u001b[0m     )\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m---> 96\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     97\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLLMMathChain._evaluate(\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpression\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m) raised error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     98\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Please try again with a valid numerical expression\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     99\u001b[0m     )\n\u001b[0;32m    101\u001b[0m \u001b[38;5;66;03m# Remove any leading and trailing brackets from the output\u001b[39;00m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m re\u001b[38;5;241m.\u001b[39msub(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m^\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m[|\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m]$\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, output)\n",
            "\u001b[1;31mValueError\u001b[0m: LLMMathChain._evaluate(\"\nGDP_US_2022 + 5\n\") raised error: 'GDP_US_2022'. Please try again with a valid numerical expression"
          ]
        }
      ],
      "source": [
        "from langchain.agents import AgentType, initialize_agent, load_tools\n",
        "from langchain.llms import OpenAI\n",
        "\n",
        "llm = OpenAI(temperature=0)\n",
        "#Google Search API\n",
        "# The tools we'll give the Agent access to. Note that the 'llm-math' tool uses an LLM, so we need to pass that in.\n",
        "tools = load_tools([\"serpapi\", \"llm-math\"], llm=llm)\n",
        "\n",
        "# Finally, let's initialize an agent with the tools, the language model, and the type of agent we want to use.\n",
        "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n",
        "\n",
        "# Let's test it out!\n",
        "agent.run(\"What was the GDP of US in 2022 plus 5?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "07d1ce0e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m I should use a calculator to find the common denominator\n",
            "Action: Calculator\n",
            "Action Input: 2/5\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3mAnswer: 0.4\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I should convert the decimal to a fraction\n",
            "Action: Calculator\n",
            "Action Input: 0.4\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3mAnswer: 0.4\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I should multiply the fraction by 10 to get rid of the decimal\n",
            "Action: Calculator\n",
            "Action Input: 0.4 * 10\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3mAnswer: 4.0\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I should simplify the fraction\n",
            "Action: Calculator\n",
            "Action Input: 4/10\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3mAnswer: 0.4\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
            "Final Answer: The common denominator of 2 and 5 in fraction is 4/10 or 0.4.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'The common denominator of 2 and 5 in fraction is 4/10 or 0.4.'"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent.run(\"what is the common denominator of 2 and 5 in fraction\")\n",
        "# agent(\n",
        "#     {\n",
        "#         \"input\": \"who is the current leader of Japan? What is the largest prime number that is smaller than their age?\"\n",
        "#     }\n",
        "# )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09cd3a12",
      "metadata": {
        "id": "09cd3a12"
      },
      "source": [
        "#### Wikipedia and llm-math tool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "TpJ3gA4YZKMx",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TpJ3gA4YZKMx",
        "outputId": "7b652dce-eac8-421c-9c87-7e794b610da5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting wikipedia\n",
            "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting beautifulsoup4\n",
            "  Downloading beautifulsoup4-4.12.2-py3-none-any.whl (142 kB)\n",
            "     ---------------------------------------- 0.0/143.0 kB ? eta -:--:--\n",
            "     -- ------------------------------------- 10.2/143.0 kB ? eta -:--:--\n",
            "     ------- ----------------------------- 30.7/143.0 kB 325.1 kB/s eta 0:00:01\n",
            "     ------- ----------------------------- 30.7/143.0 kB 325.1 kB/s eta 0:00:01\n",
            "     ------- ----------------------------- 30.7/143.0 kB 325.1 kB/s eta 0:00:01\n",
            "     ------- ----------------------------- 30.7/143.0 kB 325.1 kB/s eta 0:00:01\n",
            "     ------- ----------------------------- 30.7/143.0 kB 325.1 kB/s eta 0:00:01\n",
            "     ---------- -------------------------- 41.0/143.0 kB 108.9 kB/s eta 0:00:01\n",
            "     ---------- -------------------------- 41.0/143.0 kB 108.9 kB/s eta 0:00:01\n",
            "     --------------- --------------------- 61.4/143.0 kB 130.9 kB/s eta 0:00:01\n",
            "     ------------------ ------------------ 71.7/143.0 kB 131.0 kB/s eta 0:00:01\n",
            "     ----------------------- ------------- 92.2/143.0 kB 154.0 kB/s eta 0:00:01\n",
            "     ----------------------- ------------- 92.2/143.0 kB 154.0 kB/s eta 0:00:01\n",
            "     ---------------------------- ------- 112.6/143.0 kB 167.9 kB/s eta 0:00:01\n",
            "     ------------------------------ ----- 122.9/143.0 kB 171.4 kB/s eta 0:00:01\n",
            "     --------------------------------- -- 133.1/143.0 kB 174.5 kB/s eta 0:00:01\n",
            "     ------------------------------------ 143.0/143.0 kB 173.3 kB/s eta 0:00:00\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in c:\\users\\adity\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from wikipedia) (2.31.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\adity\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\adity\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.3.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\adity\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2023.11.17)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\adity\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.1.0)\n",
            "Collecting soupsieve>1.2\n",
            "  Downloading soupsieve-2.5-py3-none-any.whl (36 kB)\n",
            "Installing collected packages: soupsieve, beautifulsoup4, wikipedia\n",
            "  Running setup.py install for wikipedia: started\n",
            "  Running setup.py install for wikipedia: finished with status 'done'\n",
            "Successfully installed beautifulsoup4-4.12.2 soupsieve-2.5 wikipedia-1.4.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  DEPRECATION: wikipedia is being installed using the legacy 'setup.py install' method, because it does not have a 'pyproject.toml' and the 'wheel' package is not installed. pip 23.1 will enforce this behaviour change. A possible replacement is to enable the '--use-pep517' option. Discussion can be found at https://github.com/pypa/pip/issues/8559\n",
            "\n",
            "[notice] A new release of pip is available: 23.0.1 -> 23.3.2\n",
            "[notice] To update, run: C:\\Users\\adity\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install wikipedia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "14d06ce6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "14d06ce6",
        "outputId": "66393d9e-a6bf-488a-9adb-14a85ddd4d52",
        "scrolled": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m I should use Wikipedia to find the release year of the film and then use a calculator to raise it to the 0.43 power.\n",
            "Action: Wikipedia\n",
            "Action Input: Departed\u001b[0m"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\adity\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"html.parser\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
            "\n",
            "The code that caused this warning is on line 389 of the file C:\\Users\\adity\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"html.parser\"' to the BeautifulSoup constructor.\n",
            "\n",
            "  lis = BeautifulSoup(html).find_all('li')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Observation: \u001b[36;1m\u001b[1;3mPage: The Departed\n",
            "Summary: The Departed is a 2006 American crime thriller film directed by Martin Scorsese and written by William Monahan. It is both a remake of the 2002 Hong Kong film Infernal Affairs and also loosely based on the real-life Boston Winter Hill Gang; the character Colin Sullivan is based on the corrupt FBI agent John Connolly, while the character Frank Costello is based on Irish-American gangster and crime boss Whitey Bulger. The film stars Leonardo DiCaprio, Matt Damon, Jack Nicholson, and Mark Wahlberg, with Martin Sheen, Ray Winstone, Vera Farmiga, Alec Baldwin, Anthony Anderson and James Badge Dale in supporting roles.\n",
            "The film takes place in Boston and the surrounding metro area, primarily in the South Boston neighborhood. Irish Mob boss Frank Costello (Nicholson) plants Colin Sullivan (Damon) as a spy within the Massachusetts State Police; simultaneously, the police assign undercover state trooper Billy Costigan (DiCaprio) to infiltrate Costello's mob crew. When both sides realize the situation, Sullivan and Costigan each attempt to discover the other's identity before they are found out.\n",
            "The Departed was a critical and commercial success, receiving acclaim for its direction, performances (particularly of DiCaprio, Nicholson, and Wahlberg), screenplay, and editing.\n",
            "It won several accolades, including four Oscars at the 79th Academy Awards: for Best Picture, Best Director, Best Adapted Screenplay, and Best Film Editing. It became Scorsese's first and, to date, only personal Oscar win; Wahlberg was also nominated for Best Supporting Actor. The film also received six nominations at the 64th Golden Globe Awards, six nominations at the 60th British Academy Film Awards, and two nominations at the 13th Screen Actors Guild Awards. DiCaprio was nominated for Golden Globe Award for Best Actor – Motion Picture Drama (also nominated that year in the same category for Blood Diamond), BAFTA Award for Best Actor in a Leading Role and Screen Actors Guild Award for Outstanding Performance by a Male Actor in a Supporting Role for his performance.\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m Now that I know the release year, I can use a calculator to raise it to the 0.43 power.\n",
            "Action: Calculator\n",
            "Action Input: 2006 ^ 0.43\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3mAnswer: 26.30281917656938\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
            "Final Answer: 26.30281917656938\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'26.30281917656938'"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# install this package: pip install wikipedia\n",
        "\n",
        "# The tools we'll give the Agent access to. Note that the 'llm-math' tool uses an LLM, so we need to pass that in.\n",
        "tools = load_tools([\"wikipedia\", \"llm-math\"], llm=llm)\n",
        "\n",
        "# Finally, let's initialize an agent with the tools, the language model, and the type of agent we want to use.\n",
        "agent = initialize_agent(\n",
        "    tools,\n",
        "    llm,\n",
        "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "# Let's test it out!\n",
        "agent.run(\"In what year was the film Departed with Leopnardo Dicaprio released? What is this year raised to the 0.43 power?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6be7ee7",
      "metadata": {
        "id": "b6be7ee7"
      },
      "source": [
        "##**Step 07: Memory**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "-WkJqQzRZaXL",
      "metadata": {
        "id": "-WkJqQzRZaXL"
      },
      "source": [
        "Chatbot application like ChatGPT, you will notice that it remember past information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "Iqunzha0Ztuz",
      "metadata": {
        "id": "Iqunzha0Ztuz"
      },
      "outputs": [],
      "source": [
        "from langchain.llms import OpenAI\n",
        "\n",
        "llm = OpenAI(temperature=0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "NE-poGM1Zxss",
      "metadata": {
        "id": "NE-poGM1Zxss"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "prompt_template_name = PromptTemplate(\n",
        "    input_variables =['cuisine'],\n",
        "    template = \"I want to open a restaurant for {cuisine} food. Suggest a fency name for this.\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "2acab5d0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2acab5d0",
        "outputId": "fda56143-b010-46bd-80d6-e76e2e00e46f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\"La Cantina de México\"\n"
          ]
        }
      ],
      "source": [
        "from langchain.chains import LLMChain\n",
        "\n",
        "chain = LLMChain(llm=llm,prompt=prompt_template_name)\n",
        "name = chain.run(\"Mexican\")\n",
        "print(name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "5bc200f9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bc200f9",
        "outputId": "ea41224f-744f-4ffc-eb07-c56d1f142b5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\"Maharaja's Palace\"\n"
          ]
        }
      ],
      "source": [
        "name = chain.run(\"Indian\")\n",
        "print(name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "229a6888",
      "metadata": {
        "id": "229a6888"
      },
      "outputs": [],
      "source": [
        "chain.memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "f492fb5a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f492fb5a",
        "outputId": "a52a148d-856e-4738-9097-e7acbd888137",
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "NoneType"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(chain.memory)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "871492be",
      "metadata": {
        "id": "871492be"
      },
      "source": [
        "##**ConversationBufferMemory**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "coQKpk8jZ8zz",
      "metadata": {
        "id": "coQKpk8jZ8zz"
      },
      "source": [
        "We can attach memory to remember all previous conversation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "53eea298",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53eea298",
        "outputId": "12414c0e-4b03-45c4-bcb1-a6d638707f58"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\"La Fiesta de Sabor\" \n",
            "\n"
          ]
        }
      ],
      "source": [
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "memory = ConversationBufferMemory()\n",
        "\n",
        "chain = LLMChain(llm=llm, prompt=prompt_template_name, memory=memory)\n",
        "name = chain.run(\"Mexican\")\n",
        "print(name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "0de5d50b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0de5d50b",
        "outputId": "5100f20f-aa5d-4364-caa6-15ed0a992cd3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\"Oasis Eats\"\n"
          ]
        }
      ],
      "source": [
        "name = chain.run(\"Arabic\")\n",
        "print(name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "5cc88888",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cc88888",
        "outputId": "2c23bc77-ced6-4b15-db3f-b3f3a9bd7962",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Human: Mexican\n",
            "AI: \n",
            "\n",
            "\"La Fiesta de Sabor\" \n",
            "\n",
            "Human: Arabic\n",
            "AI: \n",
            "\n",
            "\"Oasis Eats\"\n"
          ]
        }
      ],
      "source": [
        "print(chain.memory.buffer)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0a88b5b",
      "metadata": {
        "id": "a0a88b5b"
      },
      "source": [
        "##**ConversationChain**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "FyFmOOemaVxb",
      "metadata": {
        "id": "FyFmOOemaVxb"
      },
      "source": [
        "Conversation buffer memory goes growing endlessly\n",
        "\n",
        "Just remember last 5 Conversation Chain\n",
        "\n",
        "Just remember last 10-20 Conversation Chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "id": "687ddd2f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "687ddd2f",
        "outputId": "aa545034-f348-48ac-d04d-35e6c5e5d3f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "{history}\n",
            "Human: {input}\n",
            "AI:\n"
          ]
        }
      ],
      "source": [
        "from langchain.chains import ConversationChain\n",
        "\n",
        "convo = ConversationChain(llm=OpenAI(temperature=0.7))\n",
        "print(convo.prompt.template)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "id": "47ad5062",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "47ad5062",
        "outputId": "3c5bd147-f4a6-4237-ebd8-ab75ffe29ba2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "' The first cricket world cup was won by the West Indies in 1975. It was held in England and was a 60-over tournament. The West Indies team defeated Australia by 17 runs in the final. The captain of the West Indies team was Clive Lloyd and the top scorer of the tournament was Glenn Turner from New Zealand with 333 runs.'"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "convo.run(\"Who won the first cricket world cup?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "id": "03c80b54",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "03c80b54",
        "outputId": "f7a69def-43ef-4d4d-fbd7-9125d401efb4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'  5+5 is equal to 10.'"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "convo.run(\"How much is 5+5?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "id": "07342f88",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "07342f88",
        "outputId": "a75a8d17-3730-494e-ebfa-acdf34b01890"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "' The captain of the winning team was Clive Lloyd. He was a left-handed batsman and a slow left-arm orthodox bowler. He played for the West Indies from 1966 to 1985 and was known for his aggressive and powerful style of play. He also led the West Indies to victory in the second cricket world cup in 1979.'"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "convo.run(\"Who was the captain ofthe winning team?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "4e459d07",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4e459d07",
        "outputId": "ff9aa831-41c2-4cc8-961c-ee09b51d666d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Human: Who won the first cricket world cup?\n",
            "AI:  The first cricket world cup was won by the West Indies in 1975. It was held in England and was a 60-over tournament. The West Indies team defeated Australia by 17 runs in the final. The captain of the West Indies team was Clive Lloyd and the top scorer of the tournament was Glenn Turner from New Zealand with 333 runs.\n",
            "Human: How much is 5+5?\n",
            "AI:   5+5 is equal to 10.\n",
            "Human: Who was the captain ofthe winning team?\n",
            "AI:  The captain of the winning team was Clive Lloyd. He was a left-handed batsman and a slow left-arm orthodox bowler. He played for the West Indies from 1966 to 1985 and was known for his aggressive and powerful style of play. He also led the West Indies to victory in the second cricket world cup in 1979.\n"
          ]
        }
      ],
      "source": [
        "print(convo.memory.buffer)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "feaa3abd",
      "metadata": {
        "id": "feaa3abd"
      },
      "source": [
        "##**ConversationBufferWindowMemory**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "id": "460eb33c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "460eb33c",
        "outputId": "6721c647-5fcb-4ab2-af9f-b8847cfb3ca5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\" The first Cricket World Cup was held in 1975 and was won by the West Indies. They defeated Australia in the finals by 17 runs. The match took place at Lord's Cricket Ground in London, England. The West Indies team was led by captain Clive Lloyd and included players such as Viv Richards, Gordon Greenidge, and Andy Roberts. The tournament featured 8 teams, including England, New Zealand, Pakistan, and India. The final was a thrilling match, with the West Indies setting a target of 291 runs for Australia to chase. Australia put up a strong fight, but ultimately fell short. This victory marked the beginning of the West Indies' dominance in cricket, as they went on to win the next two World Cups in 1979 and 1983.\""
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain.memory import ConversationBufferWindowMemory\n",
        "\n",
        "memory = ConversationBufferWindowMemory(k=2)\n",
        "\n",
        "convo = ConversationChain(\n",
        "    llm=OpenAI(temperature=0.7),\n",
        "    memory=memory\n",
        ")\n",
        "convo.run(\"Who won the first cricket world cup?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "id": "d395beaf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "d395beaf",
        "outputId": "a36dcffc-3bc7-4d90-e359-6e4585b9b29d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "' 5+5 is equal to 10.'"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "convo.run(\"How much is 5+5?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "id": "93b24745",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "93b24745",
        "outputId": "d22b9d2c-9fcc-4181-a130-8911c4177c30"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "' The captain of the winning team was Clive Lloyd.'"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "convo.run(\"Who was the captain of the winning team?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "id": "K63Ie5FTvjzo",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K63Ie5FTvjzo",
        "outputId": "312bd568-f5bd-4af2-9d4a-c871e1e6f7d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Human: How much is 5+5?\n",
            "AI:  5+5 is equal to 10.\n",
            "Human: Who was the captain of the winning team?\n",
            "AI:  The captain of the winning team was Clive Lloyd.\n"
          ]
        }
      ],
      "source": [
        "print(convo.memory.buffer)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mkFhYXKUmnDO",
      "metadata": {
        "id": "mkFhYXKUmnDO"
      },
      "source": [
        "#**Step 08: Document Loaders**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "id": "-9WXxhHCZtTn",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-9WXxhHCZtTn",
        "outputId": "47b35373-1405-47f2-e3b6-f56ccbddf6f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pypdf\n",
            "  Downloading pypdf-3.17.4-py3-none-any.whl (278 kB)\n",
            "     ---------------------------------------- 0.0/278.2 kB ? eta -:--:--\n",
            "     ---------------------------------------- 0.0/278.2 kB ? eta -:--:--\n",
            "     ---------------------------------------- 0.0/278.2 kB ? eta -:--:--\n",
            "     ---------------------------------------- 0.0/278.2 kB ? eta -:--:--\n",
            "     ---------------------------------------- 0.0/278.2 kB ? eta -:--:--\n",
            "     ---------------------------------------- 0.0/278.2 kB ? eta -:--:--\n",
            "     - -------------------------------------- 10.2/278.2 kB ? eta -:--:--\n",
            "     - -------------------------------------- 10.2/278.2 kB ? eta -:--:--\n",
            "     ---- -------------------------------- 30.7/278.2 kB 187.9 kB/s eta 0:00:02\n",
            "     ---- -------------------------------- 30.7/278.2 kB 187.9 kB/s eta 0:00:02\n",
            "     ---- -------------------------------- 30.7/278.2 kB 187.9 kB/s eta 0:00:02\n",
            "     ---- -------------------------------- 30.7/278.2 kB 187.9 kB/s eta 0:00:02\n",
            "     ----- ------------------------------- 41.0/278.2 kB 109.3 kB/s eta 0:00:03\n",
            "     ----- ------------------------------- 41.0/278.2 kB 109.3 kB/s eta 0:00:03\n",
            "     -------- ---------------------------- 61.4/278.2 kB 136.5 kB/s eta 0:00:02\n",
            "     -------- ---------------------------- 61.4/278.2 kB 136.5 kB/s eta 0:00:02\n",
            "     ---------- -------------------------- 81.9/278.2 kB 148.1 kB/s eta 0:00:02\n",
            "     ---------- -------------------------- 81.9/278.2 kB 148.1 kB/s eta 0:00:02\n",
            "     ------------ ------------------------ 92.2/278.2 kB 141.7 kB/s eta 0:00:02\n",
            "     --------------- -------------------- 122.9/278.2 kB 171.7 kB/s eta 0:00:01\n",
            "     ------------------ ----------------- 143.4/278.2 kB 189.4 kB/s eta 0:00:01\n",
            "     --------------------- -------------- 163.8/278.2 kB 204.8 kB/s eta 0:00:01\n",
            "     ---------------------- ------------- 174.1/278.2 kB 205.8 kB/s eta 0:00:01\n",
            "     ------------------------- ---------- 194.6/278.2 kB 218.6 kB/s eta 0:00:01\n",
            "     ----------------------------- ------ 225.3/278.2 kB 237.3 kB/s eta 0:00:01\n",
            "     --------------------------------- -- 256.0/278.2 kB 257.9 kB/s eta 0:00:01\n",
            "     -----------------------------------  276.5/278.2 kB 275.0 kB/s eta 0:00:01\n",
            "     ------------------------------------ 278.2/278.2 kB 259.9 kB/s eta 0:00:00\n",
            "Installing collected packages: pypdf\n",
            "Successfully installed pypdf-3.17.4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.0.1 -> 23.3.2\n",
            "[notice] To update, run: C:\\Users\\adity\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install pypdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wqlRJc7DmtwA",
      "metadata": {
        "id": "wqlRJc7DmtwA"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import PyPDFLoader\n",
        "\n",
        "loader = PyPDFLoader(\"content.pdf\")\n",
        "pages = loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "XGTtdS26mt0_",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGTtdS26mt0_",
        "outputId": "93d3e794-15c8-43a7-9579-7f28939a7d03"
      },
      "outputs": [],
      "source": [
        "pages"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
